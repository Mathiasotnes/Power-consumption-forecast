{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from utils import WindowGenerator\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import IPython\n","import matplotlib.pyplot as plt\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import data\n","features = ['NO1_consumption', \n","            'NO1_temperature', \n","            'time_of_day', \n","            'time_of_week', \n","            'time_of_year', \n","            'NO1_consumption_lag_24', \n","            'NO1_temperature_lag_24', \n","            'NO1_consumption_mean_24', \n","            'NO1_temperature_mean_24']\n","\n","train_df = pd.read_csv('./data/train.csv')[features]\n","test_df = pd.read_csv('./data/test.csv')[features]\n","val_df = pd.read_csv('./data/val.csv')[features]"]},{"cell_type":"markdown","metadata":{},"source":["## WindowGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create window generator\n","window = WindowGenerator(   input_width=24, \n","                            label_width=1, \n","                            shift=1,\n","                            train_df=train_df,\n","                            val_df=val_df,\n","                            test_df=test_df,\n","                            label_columns=['NO1_consumption'])\n","window"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split data into windows\n","# Stack three slices, the length of the total window.\n","example_window = tf.stack([np.array(train_df[:window.total_window_size]),\n","                           np.array(train_df[100:100+window.total_window_size]),\n","                           np.array(train_df[200:200+window.total_window_size])])\n","\n","example_inputs, example_labels = window.split_window(example_window)\n","window.example = example_inputs, example_labels\n","\n","print('All shapes are: (batch, time, features)')\n","print(f'Window shape: {example_window.shape}')\n","print(f'Inputs shape: {example_inputs.shape}')\n","print(f'Labels shape: {example_labels.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","window.plot()"]},{"cell_type":"markdown","metadata":{},"source":["## Long Short-Term Memory model (LSTM)\n","#### Single-step"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wide_window = WindowGenerator(  input_width=24,\n","                                label_width=24,\n","                                shift=1,\n","                                train_df=train_df,\n","                                val_df=val_df,\n","                                test_df=test_df,\n","                                label_columns=['NO1_consumption'])\n","wide_window"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lstm_model = tf.keras.models.Sequential([\n","    tf.keras.layers.LSTM(32, return_sequences=True),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(units=1)\n","])\n","\n","val_performance = {}\n","performance = {}\n","\n","print('Input shape:', wide_window.example[0].shape)\n","print('Output shape:', lstm_model(wide_window.example[0]).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# history = WindowGenerator.compile_and_fit(lstm_model, wide_window)\n","# IPython.display.clear_output()\n","# lstm_model.save('./models/lstm_single_step.keras')\n","# pickle.dump(window, open('./models/lstm_single_step_history.pkl', 'wb'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load\n","lstm_model = tf.keras.models.load_model('./models/lstm_single_step.keras')\n","history = pickle.load(open('./models/lstm_single_step_history.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val_performance['LSTM'] = lstm_model.evaluate(wide_window.val)\n","performance['LSTM'] = lstm_model.evaluate(wide_window.test, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_window = tf.stack([np.array(test_df[:wide_window.total_window_size]),\n","                        np.array(test_df[100:100+wide_window.total_window_size]),\n","                        np.array(test_df[200:200+wide_window.total_window_size])])\n","\n","test_inputs, test_labels = wide_window.split_window(test_window)\n","\n","print('Test input shape:', test_inputs.shape)\n","print('Test label shape:', test_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training and validation loss\n","# history_dict = history.history\n","# loss = history_dict['loss']\n","# val_loss = history_dict['val_loss']\n","\n","# epochs = range(1, len(loss) + 1)\n","\n","# plt.figure()\n","# plt.plot(epochs, loss, 'b', label='Training loss')\n","# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","# plt.title('Training and validation loss')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot\n","wide_window.plot(model=lstm_model, denormalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Long Short-Term Memory model (LSTM)\n","#### Multi-step"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["OUT_STEPS = 24\n","multi_window = WindowGenerator(input_width=24,\n","                               label_width=OUT_STEPS,\n","                               shift=OUT_STEPS,\n","                               label_columns=['NO1_consumption'])\n","\n","example_window = tf.stack([np.array(train_df[:multi_window.total_window_size]),\n","                           np.array(train_df[100:100+multi_window.total_window_size]),\n","                           np.array(train_df[200:200+multi_window.total_window_size])])\n","\n","example_inputs, example_labels = multi_window.split_window(example_window)\n","multi_window.example = example_inputs, example_labels\n","multi_window.plot()\n","multi_window"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_features = train_df.shape[1]\n","multi_lstm_model = tf.keras.Sequential([\n","    tf.keras.layers.LSTM(64, return_sequences=True),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.LSTM(32, return_sequences=False),\n","    tf.keras.layers.Dense(OUT_STEPS*num_features,kernel_initializer=tf.initializers.zeros()),\n","    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# history = WindowGenerator.compile_and_fit(multi_lstm_model, multi_window)\n","# IPython.display.clear_output()\n","# multi_lstm_model.save('./models/lstm_multi_step.keras')\n","# pickle.dump(history, open('./models/lstm_multi_step_history.pkl', 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load\n","multi_lstm_model = tf.keras.models.load_model('./models/lstm_multi_step.keras')\n","history = pickle.load(open('./models/lstm_multi_step_history.pkl', 'rb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["multi_val_performance = {}\n","multi_performance = {}\n","\n","multi_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n","multi_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot training and validation loss\n","# history_dict = history.history\n","# loss = history_dict['loss']\n","# val_loss = history_dict['val_loss']\n","\n","# epochs = range(1, len(loss) + 1)\n","\n","# plt.figure()\n","# plt.plot(epochs, loss, 'b', label='Training loss')\n","# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","# plt.title('Training and validation loss')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["multi_window.plot(multi_lstm_model, denormalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Multi-step prediction on bidding area NO2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = ['NO2_consumption', \n","            'NO2_temperature', \n","            'time_of_day', \n","            'time_of_week', \n","            'time_of_year', \n","            'NO2_consumption_lag_24', \n","            'NO2_temperature_lag_24', \n","            'NO2_consumption_mean_24', \n","            'NO2_temperature_mean_24']\n","\n","test_df = pd.read_csv('./data/test.csv')[features]\n","val_df = pd.read_csv('./data/val.csv')[features]\n","train_df = pd.read_csv('./data/train.csv')[features]\n","\n","multi_window_no2 = WindowGenerator( input_width=24,\n","                                label_width=OUT_STEPS,\n","                                shift=OUT_STEPS,\n","                                label_columns=['NO2_consumption'],\n","                                train_df=train_df,\n","                                val_df=val_df,\n","                                test_df=test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["example_window = tf.stack([np.array(test_df[:multi_window_no2.total_window_size]),\n","                            np.array(test_df[100:100+multi_window_no2.total_window_size]),\n","                            np.array(test_df[200:200+multi_window_no2.total_window_size])])\n","\n","multi_window_no2.example = multi_window_no2.split_window(example_window)\n","\n","multi_window_no2.plot(multi_lstm_model, plot_col='NO2_consumption', denormalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network (CNN) \n","\n","#### n-in-1-out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = ['NO1_consumption',\n","            'NO1_temperature',\n","            'time_of_day',\n","            'time_of_week',\n","            'time_of_year',\n","            'NO1_consumption_lag_24',\n","            'NO1_temperature_lag_24',\n","            'NO1_consumption_mean_24',\n","            'NO1_temperature_mean_24']\n","\n","train_df = pd.read_csv('./data/train.csv')[features]\n","val_df = pd.read_csv('./data/val.csv')[features]\n","test_df = pd.read_csv('./data/test.csv')[features]\n","\n","window = WindowGenerator(   input_width=24,\n","                            label_width=1,\n","                            shift=1,\n","                            label_columns=['NO1_consumption'])"]}],"metadata":{"kernelspec":{"display_name":"TDT4173-MPC","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":2}
